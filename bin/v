#!/usr/bin/env python3

## Note: Within this script, a "path" is always absolute and `cat`-able.  Eg, s3 paths are `/mnt/s3/path/to/file`, not `s3://`.
##       That can be surprising, because this handles all s3 buckets you can access, including buckets that aren't mounted in /mnt/s3/.
##       But I prefer `/mnt/s3/` over `s3://`.

import sys, os, functools, json, datetime, itertools, re, shutil, io, argparse, textwrap
from kpa.terminal_utils import ignore_sigpipe
from pprint import pprint
from typing import List
ignore_sigpipe()
term_width = shutil.get_terminal_size().columns

SHOW_ALL = False  # This is easier than passing args down thru functions
OPEN_IN_IPYTHON = False
OPEN_IN_VISIDATA = True


def run(argv: List[str] = None):
    if argv is None: argv = sys.argv
    args = parse_args(argv)
    global SHOW_ALL, OPEN_IN_IPYTHON, OPEN_IN_VISIDATA
    if args.all: SHOW_ALL = True
    if args.py: OPEN_IN_IPYTHON = True
    if args.vd: OPEN_IN_VISIDATA = True
    if not args.path and not sys.stdin.isatty(): show_lines(read_stdin_lines_and_switch_to_tty())
    else: show_path(args.path or '.')

def parse_args(argv: List[str] = None) -> argparse.Namespace:
    if argv is None: argv = sys.argv
    parser = argparse.ArgumentParser(
        prog='v',
        usage=textwrap.dedent('''
          v /path/to/dir/         Lists files, like `ls`
          v /path/to/d            Shows completions, like `ls /path/to/d*`
          v /path/to/file         Shows the file, with a spreadsheet for tabular data
          cat file | v            Same as `v file`

        This script handles gzip and s3://
        '''),
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument('-a', '--all', action='store_true', help='By default, output is truncated to fit your terminal.  This option outputs the full result.')
    parser.add_argument('--py', action='store_true', help='Open the result in IPython.')
    parser.add_argument('--vd', action='store_true', help='Open the result in VisiData.')
    parser.add_argument('path', nargs='?', help=argparse.SUPPRESS)
    return parser.parse_args()



def show_path(path:str):
    path = get_absolute_path(path); assert not path.endswith('/')
    if path == '/mnt/s3': [print(f' - /mnt/s3/{bucket}/') for bucket in s3_list_all_buckets()]
    elif path.startswith('/mnt/s3/'): show_s3_path(path)
    elif os.path.isfile(path): show_file(path)
    elif os.path.isdir(path): show_dir(path)
    else: show_completions(path)

def show_s3_path(path:str):
    bucket_and_key = remove_required_prefix(path, '/mnt/s3/')
    bucket, key = bucket_and_key.split('/', 1) if '/' in bucket_and_key else (bucket_and_key, '')
    if s3_exists(bucket, key): show_s3_file(bucket, key)
    elif s3_exists(bucket, key+'/'): show_s3_dir(bucket, key+'/')
    else: show_s3_completions(bucket, key)

def show_s3_file(bucket:str, key:str):
    print(f'=> File /mnt/s3/{bucket}/{key}')
    print(' => Created', s3_get_object(bucket, key)['LastModified'].strftime('%Y-%m-%d_%H:%M:%S'))
    length = int(s3_get_object(bucket, key)['ContentLength'])
    print(f' => {length:,} bytes')
    #pprint(s3_get_object(bucket, key))
    if length:
        show_file(f'/mnt/s3/{bucket}/{key}')

def show_s3_dir(bucket:str, key:str):
    print(f'=> Dir /mnt/s3/{bucket}/{key}')
    print(' => mtime =', datetime.datetime.fromtimestamp(int(s3_get_object(bucket, key)['Metadata']['mtime'])).strftime('%Y-%m-%d_%H:%M:%S'))
    show_pathlist(s3_list_dir(bucket, key, output_trailing_slash=True), shared_prefix=f'/mnt/s3/{bucket}/{key}')

def show_s3_completions(bucket:str, key:str):
    print(f'=> Completions of /mnt/s3/{bucket}/{key}')
    show_pathlist(s3_list_dir(bucket, key, output_trailing_slash=True, partial_filename=True), shared_prefix=f'/mnt/s3/{bucket}/{key}')

def show_file(path:str):
    try:
        with smarter_open(path, 'rt') as f:
            lines = list(f) if SHOW_ALL else list(itertools.islice(f, 0, 50))  # TODO: Configure with `-n 50`
    except UnicodeDecodeError:
        with smarter_open(path, 'rb') as f:
            print(repr(f.read(500)))
    else:
        show_lines(lines)

def show_dir(path:str):
    show_pathlist([f'{path}/{name}' for name in os.listdir(path)], shared_prefix=path)

def show_completions(path:str):
    dir_path, basename = os.path.split(path)
    show_pathlist([f'{dir_path}/{name}' for name in os.listdir(dir_path) if name.startswith(basename)], shared_prefix=path)



## Utils:

def show_lines(lines:List[str]):
    for delim in '\t, ;|':
        ## TODO: Handle quotes
        ## TODO: Detect whether lines[0] is a header or just a row
        ## Ignore # lines when detecting a table
        hash_lines = []
        for line in lines:
            if not line.startswith('#'): break
            hash_lines.append(line)
        nohash_lines = lines[len(hash_lines):]

        if delim in nohash_lines[0]:
            num_fields = nohash_lines[0].count(delim)
            if all(line.count(delim) == num_fields for line in nohash_lines):
                good_hash_lines, bad_hash_lines = [], []
                for line in hash_lines:
                    if line.count(delim) == num_fields: good_hash_lines.append(line)
                    else: bad_hash_lines.append(line)
                for line in bad_hash_lines: print(line)
                table = [line.rstrip('\n').split(delim) for line in good_hash_lines+nohash_lines]
                show_table(table)
                return
    for line in lines: print(line.rstrip('\n'))

def show_table(table:List[List[str]]):
    if OPEN_IN_IPYTHON:
        import IPython
        df = get_df(table)
        print('>>> df'); print(df); print()
        IPython.start_ipython(argv=['--no-confirm-exit'], display_banner=False, user_ns={'df':df})
    else:
        column_widths = [0]*len(table[0])
        for colidx in range(len(table[0])):
            cell_widths = sorted(len(row[colidx]) for row in table)
            column_widths[colidx] = max(4, cell_widths[len(table)*9//10]) + 2
        if OPEN_IN_VISIDATA or len(table)>100 or sum(column_widths) + len(table[0]) > term_width or sum(len(colname)+1 for colname in table[0]) > term_width:
            ## Use VisiData for big tables:
            print('VisiData column commands:  F=tabulate.  ]=sort.  -=hide.')
            print('VisiData sheet commands:  C=summarize_columns.  q=close.  enter=focus_row.')
            import visidata
            df = get_df(table)
            visidata.vd.view_pandas(df)
        else:
            ## Just print small tables:
            print('=> Columns:')
            for colidx, colname in enumerate(table[0]):
                print(f'  - {colname}')  # TODO: show type, min-1Q-median-3Q-max NA? for num, Counter for str, CONSTANT for constant, UNIQUE for uniq str
            ## TODO: Align decimals of floats
            ## TODO: Align ints to the right, with thousands commas
            ## TODO: Center colnames
            for rowidx,row in enumerate(table):
                #if rowidx % 2 == 0: print('\x1B[1;33m', end='')
                for colidx, cell in enumerate(row):
                    width = column_widths[colidx]
                    r = f'{cell[:width]:{width}} '
                    if r.startswith('0.0') or r.startswith('-0.0'):
                        nonzero = r.lstrip('-0.')
                        zero = r[:-len(nonzero)]
                        r = '\x1B[1;32m' + zero + '\x1B[0m' + nonzero
                    print(r, end='')
                print()
                #if rowidx % 2 == 0: print('\x1B[0m', end='')

def get_df(table:List[List[str]]) -> "pd.DataFrame":
    import pandas as pd
    df = pd.DataFrame(table[1:], columns=table[0])
    return pd.read_csv(io.StringIO(df.to_csv(index=False)))  # TODO: Don't make two dataframes!

def show_pathlist(pathlist:List[str], shared_prefix:str = ''):
    if not pathlist: print(' - Nothing matched!'); return
    suffixes = [remove_required_prefix(path, shared_prefix) for path in pathlist]
    assert len(suffixes) == len(set(suffixes))
    if SHOW_ALL:
        for suf in suffixes: print(f' - {deemphasize(shared_prefix)}{suf}')
    else:
        if len(suffixes) < 50:
            for suf in suffixes: print(f' - {deemphasize(shared_prefix)}{suf}')
        else:
            ## Try replacing numbers with #.
            numless_suffixes = {re.subn(r'[0-9]+', '#', suf)[0]:suf for suf in suffixes}
            if len(numless_suffixes) < 40 and len(numless_suffixes) < len(suffixes)/2:
                for nsuf,suf in numless_suffixes.items():
                    if nsuf != suf:
                        example = re.search(r'[0-9].*[0-9]', suf).group(0)
                        print(f' - {deemphasize(shared_prefix)}{nsuf}     (eg: {example})')
                    else:
                        print(f' - {deemphasize(shared_prefix)}{suf}')
            else:
                for suf in suffixes[:20]: print(f' - {deemphasize(shared_prefix)}{suf}')
                print(f' => {len(suffixes)} total')
    if OPEN_IN_IPYTHON:
        print('=> Saved to variable `pathlist`.\n')
        import IPython
        IPython.start_ipython(argv=['--no-confirm-exit'], display_banner=False, user_ns={'pathlist':pathlist})  # TODO: import os, pathlib, etc

def emphasize(text:str) -> str:
    return '\x1B[1;34m' + text + '\x1B[0m'
def deemphasize(text:str) -> str:
    return '\x1B[1;32m' + text + '\x1B[0m'

def get_absolute_path(path:str):
    '''Like os.path.abspath(), but handles `s3://`'''
    ## TODO: support dx_proj:/dx_path
    if path.startswith('s3://'): path = '/mnt/s3/' + removeprefix(path, 's3://')
    path = os.path.abspath(path)  # Note: This strips trailing /.
    assert path.startswith('/')
    assert not path.endswith('/')
    return path

def s3_exists(bucket:str, key:str) -> bool:
    import boto3, botocore
    try: s3_get_object(bucket, key); return True
    except botocore.exceptions.ClientError: return False

def s3_list_dir(bucket:str, key:str, output_trailing_slash=False, partial_filename=False) -> List[str]:
    '''
    Returns ["{bucket}/{key}", ...].
    If `output_trailing_slash`, then directories will have a trailing slash.
    That trailing slash is needed for `s3.get_object()`.
    But a normal filesystem doesn't include trailing slashes, so it's off by default.
    If `partial_filename`, you can use enter a prefix to get completions, like `s3_list_dir('s3://rgc-ag-data/a')`.
    '''
    import botocore
    if not partial_filename and key and not key.endswith('/'): key += '/'
    result_keys = []
    try:
        for page in s3_paginate('list_objects_v2', Bucket=bucket, Prefix=key, Delimiter='/'):
            for x in page.get('CommonPrefixes',[]):
                result_keys.append(x['Prefix'])
            for x in page.get('Contents',[]):
                if x['Key'] != key:
                    result_keys.append(x['Key'])
    except botocore.exceptions.ClientError as exc:
        raise Exception(f"Failed to get s3://{bucket}/{key}") from exc
    if not output_trailing_slash:
        result_keys = [k.rstrip('/') for k in result_keys]
    return [f'/mnt/s3/{bucket}/{k}' for k in result_keys]

def s3_paginate(s3_command:str, **kwargs):
    paginator = get_s3().get_paginator(s3_command)
    return paginator.paginate(**kwargs)

def s3_list_all_buckets() -> List[str]:
    return [bucket['Name'] for bucket in get_s3().list_buckets()['Buckets']]

def s3_get_head(bucket:str, key:str, bytes:int = 500) -> bytes:
    import botocore
    try:
        return get_s3().get_object(Bucket=bucket, Key=key, Range=f'bytes=0-{bytes}')['Body'].read()
    except botocore.exceptions.ClientError as exc:
        raise Exception(f"Failed to get s3://{bucket}/{key}") from exc

@functools.lru_cache(None)
def s3_get_object(bucket:str, key:str) -> dict:
    return get_s3().get_object(Bucket=bucket, Key=key)

@functools.lru_cache(None)
def get_s3() -> "boto3.client":
    import boto3
    return boto3.client('s3')

def smarter_open(path:str, mode:str = 'r'):
    import smart_open
    if path.startswith('/mnt/s3/'):
        path = 's3://' + remove_required_prefix(path, '/mnt/s3/')
    return smart_open.smart_open(path, mode)

def removeprefix(s:str, prefix:str) -> str:
    '''Backport of str.removeprefix(prefix)'''
    if s.startswith(prefix):
        return s[len(prefix):]
    return s

def remove_required_prefix(s:str, prefix:str) -> str:
    assert s.startswith(prefix)
    return s[len(prefix):]

def read_stdin_lines_and_switch_to_tty() -> List[str]:
    data = sys.stdin.readlines()
    #data = os.fdopen(os.dup(0), 'rb')
    os.dup2(os.open("/dev/tty", os.O_RDONLY), 0)
    return data



if __name__ == '__main__':
    run()
