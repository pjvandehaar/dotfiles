#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# requirements: pip3 install beautifulsoup4 lxml boltons

# NOTE: shift-to-preview stopped working for a while but then fixed itself when I installed HighSierra (for any browser).  Don't mess with quicklook.

# NOTE: to debug problems, use `kor --ipdb <term>`, and type `interact` in ipdb shell.


# TODO: look into daum's eng-kor dictionary: <http://dic.daum.net/search.do?q=cat&dic=eng>
#    - make a list of the kinds of terms I look up, and inspect results from both.
#    - daum lets you click words in the definition to look them up (which doesn't always work great)

# TODO: look into "The Korean Learner's Dictionary": <https://krdict.korean.go.kr/eng/dicSearch/search?nation=eng&nationCode=6&ParaWordNo=&mainSearchWord=%EC%9D%98%EC%9E%90>

# TODO: look into electron-based Hain launcher <https://github.com/appetizermonster/hain-plugin-naverdictionary>



'''
TIMING:
*    50ms: python startup
*    50ms: import urllib.request
*    50ms: import bs4
|\
*|  450ms: m.endic.naver.com
|*  500ms: ac.endic.naver.com
|/
*    45ms: BeautifulSoup()
*     5ms: parse/print
(700ms)
'''

import sys
assert sys.version_info >= (3,6)

import logging
logging.basicConfig(
    level=logging.DEBUG,
    filename='/tmp/alfred-nv.log', filemode='w', # overwrite
    format='%(relativeCreated)d %(asctime)s %(message)s',
)
logging.debug('logging ready')

import itertools
import traceback
import unicodedata
import re
import urllib.parse
import argparse
import threading
import json
import xml.etree.ElementTree
from boltons import iterutils
logging.debug('imported most')
import urllib.request
from bs4 import BeautifulSoup
import bs4
logging.debug('imported urllib.request and bs4')


DEFINITION_URL_TEMPLATE = 'https://endic.naver.com/search.nhn?sLn=en&isOnlyViewEE=N&query={}'
SUGGESTION_URL_TEMPLATE = 'http://ac.endic.naver.com/ac?q={}&q_enc=utf-8&st=1100&r_format=json&r_enc=utf-8&r_lt=1000&r_unicode=0&r_escape=1'


def get_display_items(query):
    query = unicodedata.normalize('NFC', query) # b/c Alfred sends Korean through as Jamo instead of Hangul
    query = urllib.parse.quote(query)
    dfns_response, sugg_response = fetch_urls([
        DEFINITION_URL_TEMPLATE.format(query),
        SUGGESTION_URL_TEMPLATE.format(query)
    ])
    sugg = list(parse_suggestions(sugg_response))
    logging.debug(f'finished suggestions - length was {len(sugg_response)}')
    dfns = list(parse_definitions(dfns_response))
    logging.debug(f'finished definitions - length was {len(dfns_response)}')
    if len(sugg) + len(dfns) == 0:
        return [DisplayItem('no results found')]
    default_action_url = DEFINITION_URL_TEMPLATE.format(query)
    for item in dfns: item.set_default_action_url(default_action_url)
    return dfns + sugg + [DisplayItem(default_action_url, action_url=default_action_url)]

def fetch_urls(urls):
    # single-threaded debugging version:
    # handler = urllib.request.HTTPHandler(debuglevel=1)
    # opener = urllib.request.build_opener(handler)
    # urllib.request.install_opener(opener)
    # return [urllib.request.urlopen(url).read() for url in urls]
    rv = [None] * len(urls)
    def fetch_url_by_idx(idx):
        logging.debug(f'requesting {urls[idx]}')
        rv[idx] = urllib.request.urlopen(urls[idx]).read()
        logging.debug(f'received {urls[idx]}')
    threads = [threading.Thread(target=fetch_url_by_idx, args=(i,)) for i in range(len(urls))]
    for thread in threads: thread.start()
    for thread in threads: thread.join()
    for text in rv: assert text is not None, [type(text) for text in rv]
    return rv


def parse_suggestions(sugg_response):
    for idx, item_list in enumerate(json.loads(sugg_response)['items']):
        for item_pair in item_list:
            possible_query, brief_definition = item_pair[0][0], item_pair[1][0]
            url_to_pass = DEFINITION_URL_TEMPLATE.format(urllib.parse.quote(possible_query.encode('utf-8')))
            yield DisplayItem(
                '[sugg{}] '.format(idx) + possible_query,
                brief_definition,
                action_url=url_to_pass,
                autocomplete=possible_query
            )

def parse_definitions(dnfs_response):
    soup = BeautifulSoup(dnfs_response, 'lxml') # 'lxml' takes 40ms, 'html.parser' take 60ms. 'lxml' is more correct.
    logging.debug('soupified')
    sections = soup.select('div#content > div.word_num')
    if not sections: raise Exception()
    for section in sections:

        dls = section.select('> dl.list_e2')
        if dls:
            children = itertools.chain.from_iterable(dl.children or [] for dl in dls)
            children = [child for child in children if hasattr(child, 'name') and child.name in ('dt','dd')]
            num_dts = sum(child.name == 'dt' for child in children)
            assert num_dts == len(children) / 2
            for i, child in enumerate(children):
                assert (child.name == 'dt') == (i % 2 == 0)
                # must alternate <dt> <dd> <dt> <dd> ...

            for dt, dd in iterutils.chunked(children, 2):
                dt_text = dejunk(dt.select_one('span'))

                dd_displayitems = []
                if len(dd.select('> div.align_right')) == 1:
                    div = dd.select_one('> div.align_right')
                    gchildren = [gchild for gchild in div.children if gchild.name]
                    assert all(gchild.name == 'p' for gchild in gchildren)
                    while gchildren:
                        gchild = gchildren.pop(0); text = dejunk(gchild)
                        if 'bg' in gchild.attrs.get('class',[]) and gchildren and 'pad_left' in gchildren[0].attrs.get('class',[]):
                            dd_displayitems.append(DisplayItem('  + ' + text, subtext=dejunk(gchildren[0])))
                            gchildren.pop(0)
                        elif re.match(r'View \d+ more meanings :', text):
                            dd_displayitems.append(DisplayItem('  + {more}: ' + text.split(':',1)[1]))
                        elif 'category' in gchild.attrs.get('class',[]) and not gchildren and len(text) < 10: # last one
                            pass
                        else:
                            if text not in ['',':']: dd_displayitems.append(DisplayItem('  + ' + text))
                else:
                    dd_displayitems.append(DisplayItem('  + ?'))

                if len(dd_displayitems) >= 1 and dd_displayitems[0]._subtext is None:
                    yield DisplayItem(dt_text, subtext=dd_displayitems[0]._maintext)
                    yield from dd_displayitems[1:]
                elif len(dd_displayitems) > 1:
                    yield DisplayItem(dt_text)
                    yield from dd_displayitems
                else:
                    yield DisplayItem(dt_text)

            continue # done with this section

        ul = section.select('> ul.list_a')
        if ul:
            assert len(ul) == 1, (len(ul), ul)
            ul = ul[0]
            for li in ul.select('> li'):
                divs = li.select('> div')
                if len(divs) == 3:
                    assert dejunk(divs[1]) == '' and dejunk(divs[2]) == ''
                elif len(divs) == 2:
                    yield DisplayItem(dejunk(divs[0]), subtext='= ' + dejunk(divs[1]))
                else: raise Exception()
            continue # done with this section

        dls = section.select('> dl.list_e3')
        if dls:
            children = itertools.chain.from_iterable(dl.chilren or [] for dl in dls)
            children = [child for child in children if child.name in ['dt','dd']]
            for child in children:
                yield DisplayItem(dejunk(child))
            continue

        if 'display:none;' in section.attrs.get('style',''): continue
        if 'kin_schbox' in section.attrs.get('class',[]): continue
        if 'word_vlive' in section.attrs.get('class',[]): continue
        if 'word_opendict' in section.attrs.get('class',[]): continue
        raise Exception(section) # apparently we don't know what this section is

def dejunk(node, final_strip=True):
    "Convert BeautifulSoup HTML -> str by removing all the junk"
    bad_classes = ['ico_guide_ref', 'blind', 'btn_play', 'source', 'tips2', 'btn_viewtrans', 'btn_trans', 'trans_machine'] # 'fnt_k09'?
    bad_elements = ['button']
    if isinstance(node, bs4.element.Comment): return ''
    if isinstance(node, str): return str(node)
    if node.name in bad_elements: return ''
    if any(c in node.attrs.get('class',[]) for c in bad_classes): return ''
    if node.attrs.get('style','').rstrip(';') == 'display:none': return ''
    if node.name == 'sup': return '['+node.text+']'
    ret = ''
    for child in node.children: ret += dejunk(child, final_strip=False) # + ' '
    ret = re.sub(r'\s+', ' ', ret)
    return ret.strip() if final_strip else ret


def print_display_items(display_items, fmt):
    if fmt == 'plaintext': print('\n'.join(item.to_plaintext() for item in display_items))
    elif fmt == 'wrap': print('\n'.join(TerminalLineWrapper().wrap(item.to_plaintext()) for item in display_items))
    elif fmt == 'json': print('\n'.join(json.dumps(item.to_dict(), indent=1) for item in display_items))
    elif fmt == 'xml': print('<?xml version="1.0" encoding="utf-8"?>\n<items>' + ''.join(item.to_xml() for item in display_items) + '</items>')
    else: raise Exception()

class DisplayItem:
    "defines a line/row to be displayed in plaintext/xml(alfred)/json/whatever"
    def __init__(self, maintext, subtext=None, action_url=None, autocomplete=None, copytext=None):
        self._maintext, self._subtext, self._action_url, self._autocomplete, self._copytext = maintext, subtext, action_url, autocomplete, copytext
    def set_default_action_url(self, url):
        if self._action_url is None:
            self._action_url = url
    def to_plaintext(self):
        return f'{self._maintext:25} {self._subtext.strip()}' if self._subtext else self._maintext
    def to_dict(self):
        d = {'maintext': self._maintext}
        if self._subtext is not None: d['subtext'] = self._subtext
        if self._action_url is not None: d['action_url'] = self._action_url
        if self._autocomplete is not None: d['autocomplete'] = self._autocomplete
        return d
    def to_xml(self):
        E = self.E
        return xml.etree.ElementTree.tostring(
            E('item', {'autocomplete': self._autocomplete or self._maintext, 'valid':'yes'}, children=[
                E('title', text=self._maintext),
                E('subtitle', text=self._subtext),
                E('arg', text=self._action_url),
                E('text', attr={'type':'copy'}, text=self._copytext or self._maintext),
            ])).decode('utf-8')
    @staticmethod
    def E(tag, attr={}, children=[], text=None):
        elem = xml.etree.ElementTree.Element(tag, attrib=attr)
        if text: elem.text = "" + text
        for child in children: elem.append(child)
        return elem

class TerminalLineWrapper:
    def __init__(self):
        import shutil
        self.cols = shutil.get_terminal_size().columns
    def wrap(self, text):
        ret = ''
        x = self.how_many_chars_fit_in_width(text, self.cols)
        ret += (text[:x])
        while x < len(text):
            text = text[x:]
            x = self.how_many_chars_fit_in_width(text, self.cols - 8)
            ret += '\n' + ' '*8 + text[:x]
        return ret
    def how_many_chars_fit_in_width(self, s, width):
        for i, c in enumerate(s):
            width -= self.width_of_char(c)
            if width < 0: return i
        return len(s)
    def width_of_char(self, c):
        import unicodedata
        ## A: ambiguous (1 in iterm)
        ## F: full width (2)
        ## H: halfwidth (1)
        ## N : not asian (1)
        ## Na: narrow (1)
        ## W: wide (2)
        u_eaw = unicodedata.east_asian_width(c)
        if u_eaw in ('H','N','Na','A'): return 1
        elif u_eaw in ('F','W'): return 2
        else: raise Exception(ord(c))

def use_ipdb():
    def excepthook(*args, **kwargs):
        # TODO: print exception, then `input()` and let user decide whether to re-run or go to ipdb.
        from IPython.core import ultratb
        sys.excepthook = ultratb.FormattedTB(mode='Verbose', color_scheme='Linux', call_pdb=1)
        return sys.excepthook(*args, **kwargs)
    sys.excepthook = excepthook

if __name__ == u'__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('--fmt', default='wrap', choices=['plaintext', 'wrap', 'xml', 'json'])
    parser.add_argument('--test', action='store_true')
    parser.add_argument('--ipdb', action='store_true')
    parser.add_argument('query', nargs='?', default=None)
    args = parser.parse_args()
    logging.debug('args parsed')

    if args.test == bool(args.query):
        parser.print_help()
        exit(1)

    if args.test:
        queries = ['강', '조언', '뭘 해야 할까요', '그리기에', '집중할', 'cat', 'I am a potato', '추카', '중략', 'wall', 'us', 'US']
        for query in queries:
            print('TESTING QUERY:', query)
            display_items = get_display_items(query)
            print_display_items(display_items, args.fmt)
            print('')


    elif args.ipdb:
        use_ipdb()
        display_items = get_display_items(args.query)
        print_display_items(display_items, args.fmt)


    else:
        try:
            display_items = get_display_items(args.query)
            print_display_items(display_items, args.fmt)
        except Exception:
            err_filepath = '/tmp/alfred-k.err'
            with open(err_filepath, 'w') as f: f.write(traceback.format_exc())
            print_display_items([DisplayItem(f'ERROR logged to {err_filepath}', subtext='cmd-c to copy', copytext=traceback.format_exc())], args.fmt)

    logging.debug('exiting')
