#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# requirements: pip3 install beautifulsoup4 lxml

# NOTE: shift-to-preview stopped working for a while but then fixed itself when I installed HighSierra (for any browser).  Don't mess with quicklook.

# TODO: look into daum's eng-kor dictionary: <http://dic.daum.net/search.do?q=cat&dic=eng>
#    - make a list of the kinds of terms I look up, and inspect results from both.
#    - daum lets you click words in the definition to look them up (which doesn't always work great)


'''
TIMING:
*    50ms: python startup
*    50ms: import urllib.request
*    50ms: import bs4
|\
*|  450ms: m.endic.naver.com
|*  500ms: ac.endic.naver.com
|/
*    45ms: BeautifulSoup()
*     5ms: parse/print
(700ms)
'''

import sys
assert sys.version_info >= (3,6)

import logging
logging.basicConfig(
    level=logging.DEBUG,
    filename='/tmp/alfred-nv.log', filemode='w', # overwrite
    format='%(relativeCreated)d %(asctime)s %(message)s',
)
logging.debug('logging ready')

import traceback
import unicodedata
import re
import urllib.parse
import argparse
import threading
import json
import xml.etree.ElementTree
logging.debug('imported most')
import urllib.request
from bs4 import BeautifulSoup
logging.debug('imported urllib.request and bs4')


DEFINITION_URL_TEMPLATE = 'http://m.endic.naver.com/search.nhn?searchOption=all&query={}'
SUGGESTION_URL_TEMPLATE = 'http://ac.endic.naver.com/ac?q={}&q_enc=utf-8&st=1100&r_format=json&r_enc=utf-8&r_lt=1000&r_unicode=0&r_escape=1'


def get_display_items(query, handle_errors=True):
    query = unicodedata.normalize('NFC', query) # b/c Alfred sends Korean through as Jamo instead of Hangul
    query = urllib.parse.quote(query)
    dfns_response, sugg_response = fetch_urls([
        DEFINITION_URL_TEMPLATE.format(query),
        SUGGESTION_URL_TEMPLATE.format(query)
    ])
    sugg = list(parse_suggestions(sugg_response))
    logging.debug('finished suggestions')
    dfns = list(parse_definitions(dfns_response, handle_errors=handle_errors))
    logging.debug('finished definitions')
    if len(sugg) + len(dfns) == 0:
        return [DisplayItem('no results found')]
    default_action_url = DEFINITION_URL_TEMPLATE.format(query)
    for item in dfns: item.set_default_action_url(default_action_url)
    return dfns + sugg + [DisplayItem(default_action_url, action_url=default_action_url)]

def fetch_urls(urls):
    rv = [None] * len(urls)
    def fetch_url_by_idx(idx):
        logging.debug(f'requesting {urls[idx]}')
        rv[idx] = urllib.request.urlopen(urls[idx]).read()
        logging.debug(f'received {urls[idx]}')
    threads = [threading.Thread(target=fetch_url_by_idx, args=(i,)) for i in range(len(urls))]
    for thread in threads:
        thread.start()
    for thread in threads:
        thread.join()
    return rv
# def fetch_urls(urls):
#     handler = urllib.request.HTTPHandler(debuglevel=1)
#     opener = urllib.request.build_opener(handler)
#     urllib.request.install_opener(opener)
#     return [urllib.request.urlopen(url).read() for url in urls]


def parse_suggestions(sugg_response):
    for idx, item_list in enumerate(json.loads(sugg_response)['items']):
        for item_pair in item_list:
            possible_query, brief_definition = item_pair[0][0], item_pair[1][0]
            url_to_pass = DEFINITION_URL_TEMPLATE.format(urllib.parse.quote(possible_query.encode('utf-8')))
            yield DisplayItem(
                '[sugg{}] '.format(idx) + possible_query,
                brief_definition,
                action_url=url_to_pass,
                autocomplete=possible_query
            )

def parse_definitions(dnfs_response, handle_errors=True):
    soup = BeautifulSoup(dnfs_response, 'lxml') # 'lxml' takes 40ms, 'html.parser' take 60ms
    logging.debug('soupified')
    # Hopefully these are exactly the <div>s that we want.
    for section in soup.select('div#content div.entry_wrap .section_card'):
        for div in section.select('div.entry_search_word , div.entry_search_body'):
            try:
                yield from extract_display_items(div, handle_errors=handle_errors)
            except Exception as exc:
                if not handle_errors: raise
                yield DisplayItem(f'EXCEPTION: {repr(exc)} {repr(traceback.format_exc())}')
                yield DisplayItem('DIV = ' + re.sub(r'\s+', ' ', repr(div)))

def extract_display_items(div, handle_errors=True):
    definition_texts = []
    example_texts = []

    title = div.select('div.h_word')
    if len(title) != 1:
        raise Exception('no title for {}'.format(repr(title)))
    title_text = unjunk_text(title[0])

    single_dfn = div.select('p.desc_lst')
    if len(single_dfn) > 1:
        raise Exception('multiple single definitions!')
    if len(single_dfn) == 1:
        definition_texts.append(unjunk_text(single_dfn[0]))

    dfns = div.select('ul.desc_lst li')
    for dfn in dfns:
        p_descs = dfn.select('p.desc')
        if len(p_descs) == 0:
            # it's a "web collection"
            dfn_node = dfn
        elif len(p_descs) == 1:
            dfn_node = p_descs[0]
        else:
            raise Exception('there are {} `p.desc`s in {}'.format(len(p_descs), repr(dfn)))
        definition_texts.append(unjunk_text(dfn_node))

    examples = div.select('div.example_wrap')
    for example in examples:
        try:
            kor = example.select('p.example_mean')
            if len(kor) == 0: kor1 = '<n/a>'
            elif len(kor) == 1: kor1 = unjunk_text(kor[0])
            else: raise Exception(kor)

            eng = example.select('p.example_stc')
            if len(eng) == 0: eng1 = '<n/a>'
            elif len(eng) == 1: eng1 = unjunk_text(eng[0])
            else: raise Exception(eng)
            example_texts.append((kor1, eng1))
        except Exception:
            yield DisplayItem('example = [[[\n' + example.prettify() + '\n]]] caused error [[[\n' + traceback.format_exc() + ']]]')
            if not handle_errors: raise

    # make some output!
    if len(example_texts) <= 1 and sum(len(dfn_text) for dfn_text in definition_texts) <= 40:
        # we'll concatenate some definitions together to qualify for a one-liner.
        definition_texts = [' / '.join(dfn_text for dfn_text in definition_texts)]

    if len(definition_texts) == 1 and len(definition_texts[0]) > 40 and not example_texts:
        yield DisplayItem(title_text, '= ' + definition_texts[0])

    elif len(definition_texts) == 1 and len(example_texts) <= 1:
        d_text = definition_texts[0]
        e_text = ' = '.join(example_texts[0]) if len(example_texts) > 0 else ''
        yield DisplayItem(f'{title_text} = {d_text}', e_text)

    else:
        # print a title line followed by everything else.
        yield DisplayItem(f'== {title_text} ==')
        for definition_text in definition_texts:
            yield DisplayItem('    ' + definition_text)
        for example_text in example_texts:
            yield DisplayItem('    ' + example_text[0], '    ' + example_text[1])

def unjunk_text(node):
    ret = ''
    for child in node.children:
        if isinstance(child, str): ret += child
        elif 'class' in child and 'ly_cont_clt' in child['class']: continue
        elif child.name in ['a','button']: continue
        elif child.name == 'sup': ret += f'[{child.text}]'
        else: ret += child.text
    return re.sub(r'\s+', ' ', ret).strip()



def print_display_items(display_items, fmt):
    if fmt == 'plaintext': print('\n'.join(item.to_plaintext() for item in display_items))
    elif fmt == 'wrap': print('\n'.join(TerminalLineWrapper().wrap(item.to_plaintext()) for item in display_items))
    elif fmt == 'json': print('\n'.join(json.dumps(item.to_dict(), indent=1) for item in display_items))
    elif fmt == 'xml': print('<?xml version="1.0" encoding="utf-8"?>\n<items>' + ''.join(item.to_xml() for item in display_items) + '</items>')
    else: raise Exception()

class DisplayItem:
    "defines a line/row to be displayed in plaintext/xml(alfred)/json/whatever"
    def __init__(self, maintext, subtext=None, action_url=None, autocomplete=None):
        self._maintext, self._subtext, self._action_url, self._autocomplete = maintext, subtext, action_url, autocomplete
    def set_default_action_url(self, url):
        if self._action_url is None:
            self._action_url = url
    def to_plaintext(self):
        return f'{self._maintext:25} {self._subtext.strip()}' if self._subtext else self._maintext
    def to_dict(self):
        d = {'maintext': self._maintext}
        if self._subtext is not None: d['subtext'] = self._subtext
        if self._action_url is not None: d['action_url'] = self._action_url
        if self._autocomplete is not None: d['autocomplete'] = self._autocomplete
        return d
    def to_xml(self):
        E = self.E
        return xml.etree.ElementTree.tostring(
            E('item', {'autocomplete': self._autocomplete or self._maintext, 'valid':'yes'}, children=[
                E('title', text=self._maintext),
                E('subtitle', text=self._subtext),
                E('arg', text=self._action_url),
                E('text', attr={'type':'copy'}, text=self._maintext),
            ])).decode('utf-8')
    @staticmethod
    def E(tag, attr={}, children=[], text=None):
        elem = xml.etree.ElementTree.Element(tag, attrib=attr)
        if text: elem.text = "" + text
        for child in children: elem.append(child)
        return elem

class TerminalLineWrapper:
    def __init__(self):
        import shutil
        self.cols = shutil.get_terminal_size().columns
    def wrap(self, text):
        ret = ''
        x = self.how_many_chars_fit_in_width(text, self.cols)
        ret += (text[:x])
        while x < len(text):
            text = text[x:]
            x = self.how_many_chars_fit_in_width(text, self.cols - 8)
            ret += '\n' + ' '*8 + text[:x]
        return ret
    def how_many_chars_fit_in_width(self, s, width):
        for i, c in enumerate(s):
            width -= self.width_of_char(c)
            if width < 0: return i
        return len(s)
    def width_of_char(self, c):
        import unicodedata
        ## A: ambiguous (1 in iterm)
        ## F: full width (2)
        ## H: halfwidth (1)
        ## N : not asian (1)
        ## Na: narrow (1)
        ## W: wide (2)
        u_eaw = unicodedata.east_asian_width(c)
        if u_eaw in ('H','N','Na','A'): return 1
        elif u_eaw in ('F','W'): return 2
        else: raise Exception(ord(c))

def use_ipdb():
    def excepthook(*args, **kwargs):
        # TODO: print exception, then `input()` and let user decide whether to re-run or go to ipdb.
        from IPython.core import ultratb
        sys.excepthook = ultratb.FormattedTB(mode='Verbose', color_scheme='Linux', call_pdb=1)
        return sys.excepthook(*args, **kwargs)
    sys.excepthook = excepthook

if __name__ == u'__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('--fmt', default='wrap', choices=['plaintext', 'wrap', 'xml', 'json'])
    parser.add_argument('--test', action='store_true')
    parser.add_argument('--ipdb', action='store_true')
    parser.add_argument('query', nargs='?', default=None)
    args = parser.parse_args()
    logging.debug('args parsed')

    if args.test == bool(args.query):
        parser.print_help()
        exit(1)

    if args.test:
        queries = ['강', '조언', '뭘 해야 할까요', '그리기에', '집중할', 'cat', 'I am a potato', '추카']
        for query in queries:
            print('TESTING QUERY:', query)
            display_items = get_display_items(query, handle_errors=False)
            print_display_items(display_items, args.fmt)
            print('')

    elif args.ipdb:
        use_ipdb()
        display_items = get_display_items(args.query, handle_errors=False)
        print_display_items(display_items, args.fmt)

    else:
        try:
            display_items = get_display_items(args.query)
            print_display_items(display_items, args.fmt)
        except Exception:
            err_filepath = '/tmp/alfred-k.err'
            with open(err_filepath, 'w') as f: f.write(traceback.format_exc())
            print_display_items([DisplayItem(f'ERROR logged to {err_filepath}', subtext='cmd-c to copy')], args.fmt)

    logging.debug('exiting')
