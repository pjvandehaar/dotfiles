#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# NOTE: shift-to-preview stopped working for a while but then fixed itself when I installed HighSierra (for any browser).  Don't mess with quicklook.

# NOTE: to debug problems, use `kor --ipdb <term>`, and type `interact` in ipdb shell.


# TODO: look into daum's eng-kor dictionary: <http://dic.daum.net/search.do?q=cat&dic=eng>
#    - make a list of the kinds of terms I look up, and inspect results from both.
#    - daum lets you click words in the definition to look them up (which doesn't always work great)

# TODO: look into "The Korean Learner's Dictionary": <https://krdict.korean.go.kr/eng/dicSearch/search?nation=eng&nationCode=6&ParaWordNo=&mainSearchWord=%EC%9D%98%EC%9E%90>

# TODO: look into electron-based Hain launcher <https://github.com/appetizermonster/hain-plugin-naverdictionary>


import sys
assert sys.version_info >= (3,6)

import logging
logging.basicConfig(
    level=logging.DEBUG,
    filename='/tmp/alfred-kor.log', filemode='w', # overwrite
    format='%(relativeCreated)d %(asctime)s %(message)s',
)
logging.debug('logging ready')

import traceback
import unicodedata
import re
import urllib.parse
import argparse
import threading
import json
import xml.etree.ElementTree
logging.debug('imported most')
import urllib.request
logging.debug('imported urllib.request')


HTML_URL_TEMPLATE = 'https://en.dict.naver.com/#/search?query={}'
DEFINITION_URL_TEMPLATE = 'https://en.dict.naver.com/api3/enko/search?query={}&m=pc&range=all&shouldSearchVlive=true&lang=en'
SUGGESTION_URL_TEMPLATE = 'https://ac.dict.naver.com/enkodict/ac?st=11001&r_lt=11001&q={}'


def get_display_items(query):
    query = unicodedata.normalize('NFC', query) # b/c Alfred sends Jamo Korean instead of Hangul
    query = urllib.parse.quote(query)
    dfns_response, sugg_response = fetch_urls([
        DEFINITION_URL_TEMPLATE.format(query),
        SUGGESTION_URL_TEMPLATE.format(query)
    ])
    sugg = list(parse_suggestions(sugg_response))
    logging.debug(f'finished suggestions - length was {len(sugg_response)}')
    dfns = list(parse_definitions(dfns_response))
    logging.debug(f'finished definitions - length was {len(dfns_response)}')
    if len(sugg) + len(dfns) == 0:
        return [DisplayItem('no results found')]
    default_action_url = HTML_URL_TEMPLATE.format(query)
    for item in dfns: item.action_url = item.action_url or default_action_url
    return [DisplayItem(' ', action_url=default_action_url)] + dfns + sugg

def fetch_urls(urls, single_threaded=False):
    if single_threaded:
        urllib.request.install_opener(urllib.request.build_opener(urllib.request.HTTPHandler(debuglevel=1)))
        return [urllib.request.urlopen(url).read() for url in urls]
    rv = [None] * len(urls)
    def fetch_url_by_idx(idx):
        logging.debug(f'requesting {urls[idx]}')
        for _ in range(3):
            try:
                resp = urllib.request.urlopen(urls[idx])
            except Exception as exc:
                logging.debug(f'urllib exception: {str(exc)}')
            else:
                logging.debug(f'received {urls[idx]} with code {resp.getcode()}')
                text = resp.read()
                if text is not None:
                    rv[idx] = text
                    return
    threads = [threading.Thread(target=fetch_url_by_idx, args=(i,)) for i in range(len(urls))]
    for thread in threads: thread.start()
    for thread in threads: thread.join()
    for text in rv: assert text is not None, [type(text) for text in rv]
    return rv


def parse_suggestions(sugg_response):
    for idx, item_list in enumerate(json.loads(sugg_response)['items']):
        for item_pair in item_list:
            possible_query, brief_definition = item_pair[0][0], item_pair[1][0]
            url_to_pass = DEFINITION_URL_TEMPLATE.format(urllib.parse.quote(possible_query.encode('utf-8')))
            yield DisplayItem(
                '[sugg{}] '.format(idx) + possible_query,
                brief_definition,
                action_url=url_to_pass,
                autocomplete=possible_query
            )

def parse_definitions(dfns_response):
    def get_str(item, key): return item.get(key, '') or ''

    # TODO: consider using j['collectionRanking'] to sort sections
    j = json.loads(dfns_response)
    results = (j.get('searchResultMap',{}).get('searchResultListMap',{}))
    for item in results.get('WORD',{}).get('items',[]):
        if item['languageCode'] == 'ENEN': continue # don't translate Eng -> Eng

        title = dejunk_html(item['expEntry'])
        url = item['destinationLink']
        if not url.startswith('http'): url = 'https://en.dict.naver.com/' + url
        hanja = ' '.join(x['originLanguage'] for x in item.get('expAliasGeneralAlwaysList', []))

        meanings = [m for mc in item['meansCollector'] for m in mc['means']]
        if len(meanings) == 1 or sum(len(m['value']) for m in meanings) < 80:
            # TODO: show is_slang here too
            yield DisplayItem(f'{title}  [{hanja}]' if hanja else title,
                              ' ; '.join(dejunk_html(m['value']) for m in meanings),
                              action_url=url,
                              autocomplete=title)
        else:
            yield DisplayItem(title, hanja, action_url=url, autocomplete=title)
            for m in meanings:
                is_slang = '비격식' in get_str(m, 'languageGroup')
                yield DisplayItem(' '*4 +
                                  ('(slang)' if is_slang else '') +
                                  dejunk_html(get_str(m, 'value')),
                                  action_url=url, autocomplete=title)

    meaning_items = results.get('MEANING').get('items',[])
    if meaning_items:
        titles = [dejunk_html(item['expEntry']) for item in meaning_items]
        yield DisplayItem(' ; '.join(titles))

    for item in results.get('EXAMPLE',{}).get('items',[]):
        example1 = get_str(item, 'expExample1').replace('<strong>','[').replace('</strong>',']')
        example2 = get_str(item, 'expExample2').replace('<strong>','[').replace('</strong>',']')
        if not example1 or not example2: continue
        # example2 tends to be Korean, so make it bigger
        yield DisplayItem(f'eg: {example2} =', example1, autocomplete=title)

    for item in results.get('VLIVE',{}).get('items',[]):
        example1 = get_str(item, 'expExample1').replace('<strong>','[').replace('</strong>',']')
        example2 = get_str(item, 'expExample2').replace('<strong>','[').replace('</strong>',']')
        if not example1 or not example2: continue
        # example2 tends to be Korean, so make it bigger
        yield DisplayItem(f'eg, {example2} =', example1, autocomplete=title)


def dejunk_html(html):
    "Convert HTML -> str by removing all the junk"
    # TODO: handle HTML Entities like "&quot;"
    return re.sub(r'<[^>]+>', '', html)


def print_display_items(display_items, fmt):
    if fmt == 'plaintext': print('\n'.join(item.to_plaintext() for item in display_items))
    elif fmt == 'wrap': print('\n'.join(TerminalLineWrapper().wrap(item.to_plaintext()) for item in display_items))
    elif fmt == 'json': print('\n'.join(json.dumps(item.to_dict(), indent=1) for item in display_items))
    elif fmt == 'xml': print('<?xml version="1.0" encoding="utf-8"?>\n<items>' + ''.join(item.to_xml() for item in display_items) + '</items>')
    else: raise Exception()

class DisplayItem:
    "defines a line/row to be displayed in plaintext/xml(alfred)/json/whatever"
    def __init__(self, maintext, subtext=None, action_url=None, autocomplete=None, copytext=None):
        self.maintext, self.subtext, self.action_url, self.autocomplete, self.copytext = (
            maintext, subtext, action_url, autocomplete, copytext
        )
    def to_plaintext(self):
        return f'{self.maintext:25} {self.subtext.strip()}' if self.subtext else self.maintext
    def to_dict(self):
        attrs = ['maintext', 'subtext', 'action_url', 'autocomplete', 'copytext']
        attrs = [attr for attr in attrs if self.__getattribute__(attr) is not None]
        return {attr:self.__getattribute__(attr) for attr in attrs}
    def to_xml(self):
        def E(tag, attr=None, children=(), text=None):
            elem = xml.etree.ElementTree.Element(tag, attrib=attr or {})
            if text: elem.text = "" + text
            for child in children: elem.append(child)
            return elem
        return xml.etree.ElementTree.tostring(
            E('item', {'autocomplete': self.autocomplete or self.maintext, 'valid':'yes'}, children=[
                E('title', text=self.maintext),
                E('subtitle', text=self.subtext),
                E('arg', text=self.action_url),
                E('text', attr={'type':'copy'}, text=self.copytext or self.maintext),
            ])).decode('utf-8')


class TerminalLineWrapper:
    def __init__(self):
        import shutil
        self.cols = shutil.get_terminal_size().columns
    def wrap(self, text):
        ret = ''
        x = self.how_many_chars_fit_in_width(text, self.cols)
        ret += (text[:x])
        while x < len(text):
            text = text[x:]
            x = self.how_many_chars_fit_in_width(text, self.cols - 8)
            ret += '\n' + ' '*8 + text[:x]
        return ret
    def how_many_chars_fit_in_width(self, s, width):
        for i, c in enumerate(s):
            width -= self.width_of_char(c)
            if width < 0: return i
        return len(s)
    def width_of_char(self, c):
        # TODO: try `wcwidth.wcswidth(c)`.
        import unicodedata
        ## A: ambiguous (1 in iterm)
        ## F: full width (2)
        ## H: halfwidth (1)
        ## N : not asian (1)
        ## Na: narrow (1)
        ## W: wide (2)
        u_eaw = unicodedata.east_asian_width(c)
        if u_eaw in ('H','N','Na','A'): return 1
        elif u_eaw in ('F','W'): return 2
        else: raise Exception(ord(c))

def use_ipdb():
    def excepthook(*args, **kwargs):
        # TODO: print exception, then `input()` and let user decide whether to re-run or go to ipdb.
        from IPython.core import ultratb
        sys.excepthook = ultratb.FormattedTB(mode='Verbose', color_scheme='Linux', call_pdb=1)
        return sys.excepthook(*args, **kwargs)
    sys.excepthook = excepthook

if __name__ == u'__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('--fmt', default='wrap', choices=['plaintext', 'wrap', 'xml', 'json'])
    parser.add_argument('--test', action='store_true')
    parser.add_argument('--ipdb', action='store_true')
    parser.add_argument('--print-exceptions', action='store_true')
    parser.add_argument('--log-to-stderr', action='store_true')
    parser.add_argument('query', nargs='?', default=None)
    args = parser.parse_args()
    logging.debug('args parsed')

    if args.log_to_stderr:
        logging.getLogger().addHandler(logging.StreamHandler(sys.stderr))

    if args.test == bool(args.query):
        parser.print_help()
        exit(1)

    if args.test:
        queries = ['강', '조언', '뭘 해야 할까요', '그리기에', '집중할', 'cat', 'I am a potato', '추카', '중략', 'wall', 'us', 'US']
        for query in queries:
            print('TESTING QUERY:', query)
            display_items = get_display_items(query)
            print_display_items(display_items, args.fmt)
            print('')


    elif args.ipdb:
        use_ipdb()
        display_items = get_display_items(args.query)
        print_display_items(display_items, args.fmt)


    elif args.print_exceptions:
        try:
            display_items = get_display_items(args.query)
            print_display_items(display_items, args.fmt)
        except Exception:
            print(traceback.format_exc())

    else:
        try:
            display_items = get_display_items(args.query)
            print_display_items(display_items, args.fmt)
        except Exception:
            err_filepath = '/tmp/alfred-kor.err'
            with open(err_filepath, 'w') as f: f.write(traceback.format_exc())
            print_display_items([DisplayItem(f'ERROR logged to {err_filepath}', subtext='cmd-c to copy', copytext=traceback.format_exc())], args.fmt)

    logging.debug('exiting')
